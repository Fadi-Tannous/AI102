{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 5 - Benchmarking Pre-Trained Arabic OCR Models ##\n",
    "### Objetive: Exercise on Benchmarking Pre-Trained Arabic OCR Models ###\n",
    "### Dataset: Labeled Handwritten Arabic Words ###\n",
    "### Please fill in all sections that start with \"# Task\" , sections that start with \"# Step\" are  pre-implemented #######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 1 - Dependencies & Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1.1. - Install required libraries\n",
    "!pip3 install numpy matplotlib opencv-python opencv-contrib-python python-Levenshtein easyocr pytesseract transformers[torch]==4.26.0 torch torchvision \n",
    "\n",
    "# Step 1.2. - Restart Kernel Manually\n",
    "# Toolbar -> Kernel -> Restart & Clear Output -> Restart & Clear All Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "AhzI1ZLchcd8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fadi_\\AppData\\Roaming\\Python\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Step 1.3. - Import required libraries\n",
    "import matplotlib.pyplot as plt, numpy as np, glob, cv2, pandas as pd, easyocr, time, keras_ocr, pytesseract\n",
    "from Levenshtein import distance as lev\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 2 - Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6k5QaeNxhqT_",
    "outputId": "68cf2c2c-e167-4233-bd3e-7f890b803486"
   },
   "outputs": [],
   "source": [
    "# Step 2.1. Load Images and Label Files into Pandas DataFrame\n",
    "dataset_path = \"Labeled_Handwritten_Arabic_Words/\"\n",
    "id_from_path = lambda x : x.split(\"\\\\\")[1].split(\".\")[0]\n",
    "images = [{\"id\": id_from_path(path), \"img\": cv2.resize(cv2.imread(path), (128, 64), interpolation=cv2.INTER_LINEAR)} for path in glob.glob(f\"{dataset_path}/images/*.jpg\")]\n",
    "labels = [{\"id\": id_from_path(path), \"label\": open(path, encoding=\"utf8\").read().strip()} for path in glob.glob(f\"{dataset_path}/labels/*.txt\")]\n",
    "df = pd.merge(pd.DataFrame(images), pd.DataFrame(labels), on='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 3 - Benchmark EasyOcr - Calculating the Character Error Rate and Prediction Run-time\n",
    "#### More Information available @  https://pypi.org/project/easyocr/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character Error Rate: 0.37327188940092165 , Time Taken (Seconds): 4.8026206493377686\n"
     ]
    }
   ],
   "source": [
    "# Task 3.1. Instantiate EasyOCR Reader for Arabic Language\n",
    "reader = easyocr.Reader(['ar'])\n",
    "\n",
    "# Task 3.2. Store Current Time using time.time\n",
    "st = time.time()\n",
    "\n",
    "# Task 3.3. Define variables to calculate CER; two variables \n",
    "#          s_d_i captures the number of character changes required \n",
    "#          c captures the total number of characters within the ground truth\n",
    "s_d_i = 0\n",
    "c = 0\n",
    "\n",
    "# Task 3.4. Iterate through a sample of 50 images and labels\n",
    "for i, row in df.iloc[:50].iterrows():\n",
    "    # Task 3.5. Store the recognized arabic text in a variable\n",
    "    result = reader.readtext(row['img'])\n",
    "    pred_text = result[0][1] if result else ''\n",
    "    # Task 3.6. Use Levenshtein (lev) function to calculate the number of changes required between prediction and truth\n",
    "    # Adding the value to s_d_i\n",
    "    s_d_i += lev(row['label'], pred_text)\n",
    "    # Task 3.7. Add number of characters in the original label to c\n",
    "    c += len(row['label'])\n",
    "\n",
    "# Task 3.8. Print the Calculated CER and Time Taken\n",
    "print(f\"Character Error Rate: {s_d_i/(s_d_i+c)} , Time Taken (Seconds): {time.time()-st}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 4 - Benchmark UBC-NLP/ArOCR-handwritting-v2 - calculating the Character Error Rate and Prediction Run-time\n",
    "#### More Information available @ https://huggingface.co/UBC-NLP/ArOCR-handwritting-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E1hPZfai5M3q",
    "outputId": "22f90cb9-b797-4cc3-ed8f-feb1e4b52e1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character Error Rate: 0.5915915915915916 , Time Taken (Seconds): 84.89572191238403\n"
     ]
    }
   ],
   "source": [
    "# Task 4.1. Instantiate UBC-NLP/ArOCR-handwritting-v2 using TrOCRProcessor and VisionEncoderDecoderModel\n",
    "processor = TrOCRProcessor.from_pretrained('UBC-NLP/ArOCR-handwritting-v2')\n",
    "model = VisionEncoderDecoderModel.from_pretrained('UBC-NLP/ArOCR-handwritting-v2')\n",
    "\n",
    "# Task 4.2. Store Current Time using time.time\n",
    "st = time.time()\n",
    "\n",
    "# Task 4.3. Define variables to calculate CER; two variables \n",
    "#          s_d_i captures the number of character changes required \n",
    "#          c captures the total number of characters within the ground truth\n",
    "s_d_i = 0\n",
    "c = 0\n",
    "\n",
    "# Task 4.4. Iterate through a sample of 50 images and labels\n",
    "for i, row in df.iloc[:50].iterrows():\n",
    "    # Task 4.5. Store the recognized arabic text in a variable\n",
    "    pixel_values = processor(images=row['img'], return_tensors=\"pt\").pixel_values\n",
    "    generated_ids = model.generate(pixel_values, max_length=16)\n",
    "    pred_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    # Task 4.6. Use Levenshtein (lev) function to calculate the number of changes required between prediction and truth\n",
    "    # Adding the value to s_d_i\n",
    "    s_d_i += lev(row['label'], pred_text)\n",
    "    # Task 4.7. Add number of characters in the original label to c\n",
    "    c += len(row['label'])\n",
    "\n",
    "# Task 4.8. Print the Calculated CER and Time Taken\n",
    "print(f\"Character Error Rate: {s_d_i/(s_d_i+c)} , Time Taken (Seconds): {time.time()-st}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 5 - Benchmark gagan3012/ArOCR - calculating the Character Error Rate and Prediction Run-time\n",
    "#### More Information available @ https://huggingface.co/gagan3012/ArOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character Error Rate: 0.6738609112709832 , Time Taken (Seconds): 18.45766305923462\n"
     ]
    }
   ],
   "source": [
    "# Task 5.1. Instantiate gagan3012/ArOCR using TrOCRProcessor and VisionEncoderDecoderModel\n",
    "processor = TrOCRProcessor.from_pretrained('gagan3012/ArOCR')\n",
    "model = VisionEncoderDecoderModel.from_pretrained('gagan3012/ArOCR')\n",
    "\n",
    "# Task 5.2. Store Current Time using time.time\n",
    "st = time.time()\n",
    "\n",
    "# Task 5.3. Define variables to calculate CER; two variables \n",
    "#          s_d_i captures the number of character changes required \n",
    "#          c captures the total number of characters within the ground truth\n",
    "s_d_i = 0\n",
    "c = 0\n",
    "\n",
    "# Task 5.4. Iterate through a sample of 50 images and labels\n",
    "for i, row in df.iloc[:50].iterrows():\n",
    "    # Task 5.5. Store the recognized arabic text in a variable\n",
    "    pixel_values = processor(images=row['img'], return_tensors=\"pt\").pixel_values\n",
    "    generated_ids = model.generate(pixel_values, max_length=16)\n",
    "    pred_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    # Task 5.6. Use Levenshtein (lev) function to calculate the number of changes required between prediction and truth\n",
    "    # Adding the value to s_d_i\n",
    "    s_d_i += lev(row['label'], pred_text)\n",
    "    # Task 5.7. Add number of characters in the original label to c\n",
    "    c += len(row['label'])\n",
    "\n",
    "# Task 5.8. Print the Calculated CER and Time Taken\n",
    "print(f\"Character Error Rate: {s_d_i/(s_d_i+c)} , Time Taken (Seconds): {time.time()-st}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 6 - Benchmark PyTesseract - calculating the Character Error Rate and Prediction Run-time\n",
    "#### More Information available @ https://github.com/tesseract-ocr/tesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character Error Rate: 0.4581673306772908 , Time Taken (Seconds): 1.1063807010650635\n"
     ]
    }
   ],
   "source": [
    "# Step 6.1. Instantiate PyTesseract Library\n",
    "# Follow Guide on Tesseract Installation @ https://medium.com/@marioruizgonzalez.mx/how-install-tesseract-orc-and-pytesseract-on-windows-68f011ad8b9b\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe'\n",
    "\n",
    "# Task 6.2. Store Current Time using time.time\n",
    "st = time.time()\n",
    "\n",
    "# Task 6.3. Define variables to calculate CER; two variables \n",
    "#          s_d_i captures the number of character changes required \n",
    "#          c captures the total number of characters within the ground truth\n",
    "s_d_i = 0\n",
    "c = 0\n",
    "\n",
    "# Task 6.4. Iterate through a sample of 50 images and labels\n",
    "for i, row in df.iloc[:50].iterrows():\n",
    "    # Task 6.5. Store the recognized arabic text in a variable\n",
    "    pred_text = pytesseract.image_to_string(row['img'], lang='ara').replace('\\n', '')\n",
    "    # Task 6.6. Use Levenshtein (lev) function to calculate the number of changes required between prediction and truth\n",
    "    # Adding the value to s_d_i\n",
    "    s_d_i += lev(row['label'], pred_text)\n",
    "    # Task 6.7. Add number of characters in the original label to c\n",
    "    c += len(row['label'])\n",
    "\n",
    "# Task 6.8. Print the Calculated CER and Time Taken\n",
    "print(f\"Character Error Rate: {s_d_i/(s_d_i+c)} , Time Taken (Seconds): {time.time()-st}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "OCR_Model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
