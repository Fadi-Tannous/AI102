{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ScS8QSp_eSQv"
   },
   "source": [
    "# Day 1 - Preprocessing for Arabic OCR ##\n",
    "### Objetive: Exercise on De-noising, Erosion, Dilation, and Rotation Correction ###\n",
    "### Dataset: Handwritten Arabic Image  ###\n",
    "### Please fill in all sections that start with \"# Task\" , sections that start with \"# Step\" are  pre-implemented ####### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t4qW0zGxZywM"
   },
   "source": [
    "#### Section 1 - Dependencies & Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Step 1.1. - Install required libraries\n",
    "!pip3 install numpy torch torchvision easyocr matplotlib deskew opencv-python opencv-contrib-python\n",
    "\n",
    "# Step 1.2. - Restart Kernel Manually\n",
    "# Toolbar -> Kernel -> Restart & Clear Output -> Restart & Clear All Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TEXCdTqVZn8d"
   },
   "outputs": [],
   "source": [
    "# Step 1.3. - Import required libraries\n",
    "import cv2, numpy as np, easyocr, pandas as pd, os, matplotlib.pyplot as plt\n",
    "from deskew import determine_skew\n",
    "from skimage.transform import rotate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 2 - Set up EasyOCR Arabic Recognition Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 934,
     "status": "ok",
     "timestamp": 1674973189586,
     "user": {
      "displayName": "Ibrahim Shahbaz",
      "userId": "08079577298771298538"
     },
     "user_tz": -180
    },
    "id": "erdQH1qjh6Lf",
    "outputId": "01fea149-db3f-4b56-fe2f-b365de2b925b",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Task 2.1. Instantiate easyocr.Reader for Arabic Language\n",
    "# Tutorial Available @ https://www.jaided.ai/easyocr/tutorial/\n",
    "\n",
    "\n",
    "# Task 2.2. Read handwritten_arabic.jpg using OpenCV; into variable img\n",
    "\n",
    "\n",
    "# Step 2.3. Define function to show opencv image inline using matplotlib\n",
    "def show_image(image, color=None):\n",
    "    imgplot = plt.imshow(image, cmap=color)\n",
    "    plt.show()\n",
    "\n",
    "# Task 2.4. Test function from task 2.3.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 3 - Use EasyOCR to recognize arabic text and explore the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3.1. Recognize text and explore the output format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 4 - Write a function that uses EasyOCR and prints the string in the correct order for arabic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Write a function that\n",
    "#           - Accepts an image input\n",
    "#           - Recognizes text within image using EasyOCR\n",
    "#           - Re-Orders the text output based on the x,y coordinates for each bounding box\n",
    "#           - Prints the String in the correct order \n",
    "# Step 4.1. Define the Function\n",
    "def img_to_text(img):\n",
    "    # Task 4.2. Recognize the text using EasyOCR\n",
    "\n",
    "    # Task 4.3. For each row in the extracted results extract\n",
    "    #           the minimum and maximum values of x and y\n",
    "    #           the recognized arabic sentence\n",
    "    #           Storing Results in a Pandas DataFrame\n",
    "    \n",
    "    \n",
    "    # Task 4.4. Calculate the Average Line Height as an integer; assuming each record in the dataframe is one line; height = (max_y-min_y)\n",
    "\n",
    "    # Task 4.5. Calculate the Modulus of min_y to the line height; as a proxy for line order\n",
    "\n",
    "    # Task 4.6. Sort the DataFrame by line ascending and max_x descending \n",
    "\n",
    "    # Task 4.7. Print each line of the dataframe\n",
    "    # Hint: Use df.groupby('line')\n",
    "\n",
    "\n",
    "# Task 4.8. Use img_to_text on the loaded handwritten_arabic image from Task 2.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 5 - Preprocess the handwritten_arabic image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 5.1. Apply Greyscaling using cv2.cvtColor\n",
    "\n",
    "\n",
    "# Task 5.2. Apply Binary Thresholding using cv2.adaptiveThreshold (Experiment with adaptive methods and blocks sizes)\n",
    "\n",
    "\n",
    "# Task 5.3. Apply Noise Removal \n",
    "# Task 5.3.1. Define a kernel for morphological operations\n",
    "\n",
    "# Task 5.3.2. Apply Morphological Operation using defined kernel in 5.3.1\n",
    "\n",
    "\n",
    "# Task 5.4. Perform Erosion or Dilation - as needed (required manual insepection - use function from task 2.3\n",
    "# Task 5.4.1. Define Kernel for Erosion or Dilation - Size of the Kernel directly correctly to strength\n",
    "\n",
    "# Task 5.4.2. Perform Erosion\n",
    "\n",
    "# Task 5.4.3. Perform Dilation\n",
    "\n",
    "\n",
    "# Task 5.5. Fix Rotation - Deskewing Image\n",
    "# Task 5.5.1. Determine Skew Angle \n",
    "\n",
    "# Task 5.5.2. Rotate Image to Deskew it (use variable name rotated_image to store)\n",
    "\n",
    "\n",
    "# Step 5.6. Show Final Image\n",
    "show_image(rotated_image, color='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 6 - Use img_to_text on the pre-processed handwritten_arabic image from section 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6.1. Compare the Recognized Handwritten Text from the original Image Versus the Pre-processed image\n",
    "img_to_text(img)\n",
    "print(\"------------------\")\n",
    "img_to_text(rotated_image)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "iW8DKvVCY7iB"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
