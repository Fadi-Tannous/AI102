{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 3 - EAST Text Detection Demo ##\n",
    "### Objective: Showcase Real-time EAST Text Detection (Efficient and Accurate Scene Text Detector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 1 - Dependencies & Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "!pip3 install numpy matplotlib imutils opencv-python opencv-contrib-python\n",
    "\n",
    "# Restart Kernel Manually\n",
    "# Toolbar -> Kernel -> Restart & Clear Output -> Restart & Clear All Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 216,
     "status": "ok",
     "timestamp": 1678468492755,
     "user": {
      "displayName": "Mohamed Emad Naji",
      "userId": "12565142321414984121"
     },
     "user_tz": 300
    },
    "id": "UsExZhRDo23M"
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from imutils.object_detection import non_max_suppression\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np, time, cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JMNdOu7ij-1U"
   },
   "source": [
    "#### Section 2 -  Build EAST Text Detector Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define text_detection class\n",
    "class text_detection(object):\n",
    "    \n",
    "    # Define Initialiation Function - Height and Width need to be multiples of 32\n",
    "    def __init__(self, default_height=1024, default_width=1024, min_confidence=0.5):\n",
    "        # Load Frozen EAST FCN\n",
    "        self.model = cv2.dnn.readNet(\"frozen_east_text_detection.pb\")\n",
    "        # Define EAST Output Layers\n",
    "        self.output = [\"feature_fusion/Conv_7/Sigmoid\", \"feature_fusion/concat_3\"]\n",
    "        # Store Default Width and Height\n",
    "        self.height, self.width, self.min_confidence = default_height, default_width, min_confidence\n",
    "    \n",
    "    # Define private function to pre-process image (resizing and turning to opencv blob)\n",
    "    def __preprocess_image(self, img):\n",
    "        # Resize image to default height & Width\n",
    "        img = cv2.resize(img, (self.width, self.height))\n",
    "        # Calculate image blob using cv2.dnn.blobFromImage\n",
    "        return cv2.dnn.blobFromImage(img, 1.0, (self.width, self.height), (123.68, 116.78, 103.94), swapRB=True, crop=False)\n",
    "    \n",
    "    # Define private function to parse EAST results into list of boudning box coorindates and list of confidences\n",
    "    def __parse_results(self, scores, geometry):\n",
    "        (numRows, numCols) = scores.shape[2:4]\n",
    "        rects = []\n",
    "        confidences = []\n",
    "        for y in range(0, numRows):\n",
    "            for x in range(0, numCols):\n",
    "                # Only consider bounding boxes with confidence > min_confidence\n",
    "                if scores[0, 0, y][x] >= self.min_confidence:\n",
    "                    #  Compute the sin and cosine of the rotation angle\n",
    "                    cos = np.cos(geometry[0, 4, y][x])\n",
    "                    sin = np.sin(geometry[0, 4, y][x])\n",
    "                    # Calculate the height and Width of the bounding box\n",
    "                    h = geometry[0, 0, y][x] + geometry[0, 2, y][x]\n",
    "                    w = geometry[0, 1, y][x] + geometry[0, 3, y][x]\n",
    "                    # Compute both the starting and ending (x, y)-coordinates for bounding box\n",
    "                    endX = int((x * 4.0) + (cos * geometry[0, 1, y][x]) + (sin * geometry[0, 2, y][x]))\n",
    "                    endY = int((y * 4.0) - (sin * geometry[0, 1, y][x]) + (cos * geometry[0, 2, y][x]))\n",
    "                    startX = int(endX - w)\n",
    "                    startY = int(endY - h)\n",
    "                    # Append bounding box coordinates and confidence to respective arrays\n",
    "                    rects.append((startX, startY, endX, endY))\n",
    "                    confidences.append(scores[0, 0, y][x])\n",
    "        return rects, confidences\n",
    "    \n",
    "    # Define private function to draw boxes on image using cv2.rectangle\n",
    "    def __draw_boxes(self, img, boxes):\n",
    "        for (startX, startY, endX, endY) in boxes:\n",
    "            # Calculate scale factors (ratio of original image to resized image)\n",
    "            rW = img.shape[1] / float(self.width)\n",
    "            rH = img.shape[0] / float(self.height)\n",
    "            # Draw the bounding box on the image\n",
    "            cv2.rectangle(img, (int(startX * rW), int(startY * rH)), (int(endX * rW), int(endY * rH)), (0, 255, 0), 2)\n",
    "        return img\n",
    "\n",
    "    # Define function to detect text boxes in image and return image with drawn text boxes\n",
    "    def detect(self, img):\n",
    "        self.model.setInput(self.__preprocess_image(img))\n",
    "        scores, geometry = self.model.forward(self.output)\n",
    "        rects, confidences = self.__parse_results(scores, geometry)\n",
    "        boxes = non_max_suppression(np.array(rects), probs=confidences)\n",
    "        return self.__draw_boxes(img, boxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qj5CJT77kZR6"
   },
   "source": [
    "#### Section 3 -  Test Text Detector on hadwritten_arabic.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Text Detector\n",
    "text_detector = text_detection()\n",
    "# Load Image\n",
    "image = cv2.imread(\"handwritten_arabic.jpg\")\n",
    "# Detect Boxes\n",
    "image_with_boxes = text_detector.detect(image)\n",
    "# Draw Image with Boxes\n",
    "plt.imshow(image_with_boxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4nEgiRBtkjjg"
   },
   "source": [
    "#### Section 4 -  Real-time Text Detection on Camera Feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 204,
     "status": "ok",
     "timestamp": 1678468507889,
     "user": {
      "displayName": "Mohamed Emad Naji",
      "userId": "12565142321414984121"
     },
     "user_tz": 300
    },
    "id": "zaMoKWb6st_f"
   },
   "outputs": [],
   "source": [
    "# Open Default Camera Using Opencv\n",
    "vid = cv2.VideoCapture(0)\n",
    "\n",
    "# While True (Interrupt by pressing q)\n",
    "while(True):\n",
    "    # Capture the video frame\n",
    "    ret, frame = vid.read()\n",
    "    #image = cv2.imread(\"handwritten_arabic.jpg\")\n",
    "    image_with_boxes = text_detector.detect(frame)\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', image_with_boxes)\n",
    "    # the 'q' button is set as the quitting button\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "vid.release()\n",
    "# Destroy all the windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
